{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: TITAN X (Pascal) (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "#from keras_contrib.layers.normalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from data_loader import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_data(f_mean_shift=(2,3), fvar=2, g_mean_shift=(-1,-1), gvar=0.5, num_pts=1000, mean=(0,0), var=1.0, batch_size=1):\n",
    "        #data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
    "        cov=var*np.eye(2)\n",
    "        orig = np.random.multivariate_normal(mean, cov, num_pts)\n",
    "        fmean=np.asarray(mean)+np.asarray(f_mean_shift)\n",
    "        fpts= np.random.multivariate_normal(fmean, fvar*cov, num_pts)\n",
    "        gmean=np.asarray(mean)+np.asarray(g_mean_shift)\n",
    "        gpts=np.random.multivariate_normal(gmean, gvar*cov, num_pts)\n",
    "\n",
    "        return orig, fpts, gpts\n",
    "    #where should I actually get this data? Does here work?\n",
    "orig, data_A, data_B=gen_data((10,10), 3, (-7,6), .25, 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CycleGAN():\n",
    "    def __init__(self, data_A, data_B):\n",
    "        \n",
    "        #\n",
    "        self.data_shape=(2,)\n",
    "        self.dataset_name = 'apple2orange'\n",
    "        self.data_dim=2\n",
    "\n",
    "        # Loss weights\n",
    "        self.lambda_cycle = 10.0                    # Cycle-consistency loss\n",
    "        self.lambda_id = 0.01 * self.lambda_cycle    # Identity loss\n",
    "\n",
    "        #does this optimizer make sense for non-image data?\n",
    "        #learning rate, decay rate\n",
    "        optimizer = Adam(0.001, 0.7)\n",
    "\n",
    "        #does MSE make sense with non-image data?\n",
    "        # Build and compile the discriminators\n",
    "        self.d_A = self.build_discriminator()\n",
    "        self.d_B = self.build_discriminator()\n",
    "        self.d_A.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "        self.d_B.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generators\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generators\n",
    "        self.g_AB = self.build_generator()\n",
    "        self.g_BA = self.build_generator()\n",
    "\n",
    "        # Input instances from both domains\n",
    "        datum_A = Input(shape=self.data_shape)\n",
    "        datum_B = Input(shape=self.data_shape)\n",
    "\n",
    "\n",
    "        #Is this going to work the way I have it here\n",
    "        #or should I be taking something from a batch?\n",
    "        # Translate images to the other domain\n",
    "        fake_B = self.g_AB(datum_A)\n",
    "        fake_A = self.g_BA(datum_B)\n",
    "        # Translate images back to original domain\n",
    "        reconstr_A = self.g_BA(fake_B)\n",
    "        reconstr_B = self.g_AB(fake_A)\n",
    "        # Identity mapping of images\n",
    "        datum_A_id = self.g_BA(datum_A)\n",
    "        datum_B_id = self.g_AB(datum_B)\n",
    "\n",
    "        # For the combined model we will only train the generators\n",
    "        self.d_A.trainable = False\n",
    "        self.d_B.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images\n",
    "        valid_A = self.d_A(fake_A)\n",
    "        valid_B = self.d_B(fake_B)\n",
    "\n",
    "        # Combined model trains generators to fool discriminators\n",
    "        self.combined = Model(inputs=[datum_A, datum_B],\n",
    "                              outputs=[ valid_A, valid_B,\n",
    "                                        reconstr_A, reconstr_B,\n",
    "                                        datum_A_id, datum_B_id ])\n",
    "        self.combined.compile(loss=['mse', 'mse',\n",
    "                                    'mae', 'mae',\n",
    "                                    'mae', 'mae'],\n",
    "                            loss_weights=[  1, 1,\n",
    "                                            self.lambda_cycle, self.lambda_cycle,\n",
    "                                            self.lambda_id, self.lambda_id ],\n",
    "                            optimizer=optimizer)\n",
    "\n",
    "    \n",
    "\n",
    "    def build_generator(self):\n",
    "        \"\"\"\n",
    "        Simple MLP generator for the MoG unrolled GAN toy experiment\n",
    "        \"\"\"\n",
    "\n",
    "        gen_input = Input(shape=(self.data_dim,), name=\"generator_input\")\n",
    "\n",
    "        x = Dense(2*self.data_dim)(gen_input)\n",
    "        x = Activation(\"relu\")(x)\n",
    "     #     for i in range(2):\n",
    "        x = Dense(2*self.data_dim)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(2)(gen_input)\n",
    "        \n",
    "\n",
    "        generator_model = Model(inputs=[gen_input], outputs=[x])\n",
    "        #visualize_model(generator_model)\n",
    "\n",
    "        return generator_model\n",
    "\n",
    "#        \n",
    "    def build_discriminator(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Simple MLP discriminator for the MoG unrolled GAN toy experiment\n",
    "        \"\"\"\n",
    "\n",
    "        disc_input = Input(shape=(2,), name=\"discriminator_input\")\n",
    "\n",
    "        x = Dense(2*self.data_dim)(disc_input)\n",
    "        x = Activation(\"tanh\")(x)\n",
    "    #     for i in range(2):\n",
    "        x = Dense(2*self.data_dim)(x)\n",
    "        x = Activation(\"tanh\")(x)\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation(\"sigmoid\")(x)\n",
    "\n",
    "        discriminator_model = Model(inputs=[disc_input], outputs=[x])\n",
    "        #visualize_model(discriminator_model)\n",
    "\n",
    "        #is there a difference between what this returns and the original cycelgan does?\n",
    "        return discriminator_model\n",
    "\n",
    "    \n",
    "    def train(self, epochs, batch_size=1, sample_interval=50):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,)) #+ self.disc_patch)\n",
    "        fake = np.zeros((batch_size,)) #+ self.disc_patch)\n",
    "        self.g_AB.summary()\n",
    "        self.g_BA.summary()\n",
    "        self.d_A.summary()\n",
    "        self.d_B.summary()\n",
    "        self.n_batches = int(min(len(data_A), len(data_B)) / batch_size)\n",
    "        #total_samples = self.n_batches * batch_size\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(self.n_batches-1):\n",
    "                #randomly shuffle data?\n",
    "                \n",
    "                #take the corresponding \"Batch size\" number of elements\n",
    "                batch_A = data_A[i*batch_size:(i+1)*batch_size]\n",
    "                batch_B = data_B[i*batch_size:(i+1)*batch_size]\n",
    "                #put them through this thing\n",
    "                \n",
    "                \n",
    "                # ----------------------\n",
    "                #  Train Discriminators\n",
    "                # ----------------------\n",
    "               # print(imgs_A.shape)\n",
    "\n",
    "                # Translate images to opposite domain\n",
    "                fake_B = self.g_AB.predict(batch_A)\n",
    "                fake_A = self.g_BA.predict(batch_B)\n",
    "                #print(fake_A.shape)\n",
    "                #print(fake_B.shape)\n",
    "                # Train the discriminators (original images = real / translated = Fake)\n",
    "                dA_loss_real = self.d_A.train_on_batch(batch_A, valid)\n",
    "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
    "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "\n",
    "                dB_loss_real = self.d_B.train_on_batch(batch_B, valid)\n",
    "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
    "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "\n",
    "                # Total disciminator loss\n",
    "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
    "\n",
    "\n",
    "                # ------------------\n",
    "                #  Train Generators\n",
    "                # ------------------\n",
    "\n",
    "                # Train the generators\n",
    "                g_loss = self.combined.train_on_batch([batch_A, batch_B],\n",
    "                                                        [valid, valid,\n",
    "                                                        batch_A, batch_B,\n",
    "                                                        batch_A, batch_B])\n",
    "\n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "                # Plot the progress\n",
    "                print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" \\\n",
    "                                                                        % ( epoch, epochs,\n",
    "                                                                            i, self.n_batches,\n",
    "                                                                            d_loss[0], 100*d_loss[1],\n",
    "                                                                            g_loss[0],\n",
    "                                                                            np.mean(g_loss[1:3]),\n",
    "                                                                            np.mean(g_loss[3:5]),\n",
    "                                                                            np.mean(g_loss[5:6]),\n",
    "                                                                            elapsed_time))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if i % sample_interval == 0:\n",
    "                    self.sample_data(epoch, i)\n",
    "\n",
    "    def sample_data(self, epoch, batch_i):\n",
    "        os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n",
    "       # r, c = 2, 3\n",
    "\n",
    "        orig2, pic_data_A, pic_data_B= gen_data((10,10), 3, (-7,6), .25, 1000)\n",
    "        \n",
    "    \n",
    "        # Translate images to the other domain\n",
    "        fake_B = self.g_AB.predict(pic_data_A)\n",
    "        fake_A = self.g_BA.predict(pic_data_B)\n",
    "        # Translate back to original domain\n",
    "        reconstr_A = self.g_BA.predict(fake_B)\n",
    "        reconstr_B = self.g_AB.predict(fake_A)\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(131)\n",
    "\n",
    "        ax1.scatter(pic_data_A[:, 0], pic_data_A[:,1], s=25, c='b', marker=\"s\", label='original')\n",
    "        ax1.scatter(fake_A[:,0], fake_A[:,1], c='r', s=25, marker=\"o\", label='fake')\n",
    "        ax1.scatter(reconstr_A[:,0], reconstr_A[:,1], s=25, c='g', marker=\"o\", label='reconstructed')\n",
    "        plt.legend(loc='upper left');\n",
    "        \n",
    "        ax2=fig.add_subplot(132)\n",
    "        ax2.scatter(pic_data_B[:, 0], pic_data_B[:,1], s=25, c='b', marker=\"s\", label='original')\n",
    "        ax2.scatter(fake_B[:,0], fake_B[:,1], s=25, c='r', marker=\"o\", label='fake')\n",
    "        ax2.scatter(reconstr_B[:,0], reconstr_B[:,1], s=25, c='g', marker=\"o\", label='reconstructed')\n",
    "        plt.legend(loc='upper left');\n",
    "        \n",
    "        ax3=fig.add_subplot(133)\n",
    "        ax3.scatter(pic_data_B[:, 0], pic_data_B[:,1], s=25, c='b', marker=\"s\", label='originalB')\n",
    "        ax3.scatter(fake_B[:,0], fake_B[:,1], s=25, c='r', marker=\"o\", label='fakeB')\n",
    "        ax3.scatter(reconstr_B[:,0], reconstr_B[:,1], s=25, c='g', marker=\"o\", label='reconstructedB')\n",
    "        ax3.scatter(pic_data_A[:, 0], pic_data_A[:,1], s=25, c='b', marker=\"s\", label='originalA')\n",
    "        ax3.scatter(fake_A[:,0], fake_A[:,1], c='r', s=25, marker=\"o\", label='fakeA')\n",
    "        ax3.scatter(reconstr_A[:,0], reconstr_A[:,1], s=25, c='g', marker=\"o\", label='reconstructedA')\n",
    "        plt.legend(loc='upper left');\n",
    "        \n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "        fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    gan = CycleGAN(data_A, data_B)\n",
    "    gan.train(epochs=200, batch_size=10, sample_interval=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN2():\n",
    "    def __init__(self, data_A, data_B, lr=.0002):\n",
    "        \n",
    "        #\n",
    "        self.data_shape=(2,)\n",
    "        self.dataset_name = 'apple2orange'\n",
    "        self.data_dim=2\n",
    "\n",
    "        # Loss weights\n",
    "        self.lambda_cycle = 10.0                    # Cycle-consistency loss\n",
    "        self.lambda_id = 0.01 * self.lambda_cycle    # Identity loss\n",
    "\n",
    "        optimizer = Adam(lr, 0.5)\n",
    "\n",
    "        # Build and compile the discriminators\n",
    "        self.d_A = self.build_discriminator()\n",
    "        self.d_B = self.build_discriminator()\n",
    "        self.d_A.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "        self.d_B.compile(loss='mse',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        #-------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generators\n",
    "        #-------------------------\n",
    "\n",
    "        # Build the generators\n",
    "        self.g_AB = self.build_generator()\n",
    "        self.g_BA = self.build_generator()\n",
    "\n",
    "        # Input instances from both domains\n",
    "        datum_A = Input(shape=self.data_shape)\n",
    "        datum_B = Input(shape=self.data_shape)\n",
    "\n",
    "\n",
    "        #Is this going to work the way I have it here\n",
    "        #or should I be taking something from a batch?\n",
    "        # Translate images to the other domain\n",
    "        fake_B = self.g_AB(datum_A)\n",
    "        fake_A = self.g_BA(datum_B)\n",
    "        # Translate images back to original domain\n",
    "        reconstr_A = self.g_BA(fake_B)\n",
    "        reconstr_B = self.g_AB(fake_A)\n",
    "        # Identity mapping of images\n",
    "        datum_A_id = self.g_BA(datum_A)\n",
    "        datum_B_id = self.g_AB(datum_B)\n",
    "\n",
    "        # For the combined model we will only train the generators\n",
    "        self.d_A.trainable = False\n",
    "        self.d_B.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images\n",
    "        valid_A = self.d_A(fake_A)\n",
    "        valid_B = self.d_B(fake_B)\n",
    "\n",
    "        # Combined model trains generators to fool discriminators\n",
    "        self.combined = Model(inputs=[datum_A, datum_B],\n",
    "                              outputs=[ valid_A, valid_B,\n",
    "                                        reconstr_A, reconstr_B,\n",
    "                                        datum_A_id, datum_B_id ])\n",
    "        self.combined.compile(loss=['mse', 'mse',\n",
    "                                    'mae', 'mae',\n",
    "                                    'mae', 'mae'],\n",
    "                            loss_weights=[  50, 50,\n",
    "                                            self.lambda_cycle, self.lambda_cycle,\n",
    "                                            self.lambda_id, self.lambda_id ],\n",
    "                            optimizer=optimizer)\n",
    "\n",
    "    \n",
    "\n",
    "    def build_generator(self):\n",
    "        \"\"\"\n",
    "        Simple MLP generator for the MoG unrolled GAN toy experiment\n",
    "        \"\"\"\n",
    "\n",
    "        gen_input = Input(shape=(self.data_dim,), name=\"generator_input\")\n",
    "\n",
    "        x = Dense(2*self.data_dim)(gen_input)\n",
    "        x = Activation(\"relu\")(x)\n",
    "     #     for i in range(2):\n",
    "        x = Dense(2*self.data_dim)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Dense(2)(gen_input)\n",
    "        \n",
    "\n",
    "        generator_model = Model(inputs=[gen_input], outputs=[x])\n",
    "        #visualize_model(generator_model)\n",
    "\n",
    "        return generator_model\n",
    "\n",
    "        \n",
    "#         gen_input = Input(shape=(self.data_dim,), name=\"generator_input\")\n",
    "\n",
    "#         x = Dense(4*self.data_dim)(gen_input)\n",
    "#         x = LeakyReLU(0.2)(x)\n",
    "#         x = Dropout(0.25)(x)\n",
    "#         x = Dense(2*self.data_dim)(x)\n",
    "#         x = LeakyReLU(0.2)(x)\n",
    "#         x = Dense(self.data_dim, activation='linear')(x)\n",
    "        \n",
    "#         generator_model = Model(inputs=[gen_input], outputs=[x])\n",
    "#         #visualize_model(generator_model)\n",
    "#         print(\"GENERATOR\")\n",
    "#         #model.summary()\n",
    "#         return generator_model\n",
    "        \n",
    "#        \n",
    "    def build_discriminator(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Simple MLP discriminator for the MoG unrolled GAN toy experiment\n",
    "        \"\"\"\n",
    "\n",
    "        #disc_input = Input(shape=(2,), name=\"discriminator_input\")\n",
    "        \n",
    "        \n",
    "        disc_input = Input(shape=(2,), name=\"discriminator_input\")\n",
    "\n",
    "        x = Dense(2*self.data_dim)(disc_input)\n",
    "        x = Activation(\"tanh\")(x)\n",
    "    #     for i in range(2):\n",
    "        x = Dense(2*self.data_dim)(x)\n",
    "        x = Activation(\"tanh\")(x)\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation(\"sigmoid\")(x)\n",
    "\n",
    "        discriminator_model = Model(inputs=[disc_input], outputs=[x])\n",
    "        #visualize_model(discriminator_model)\n",
    "\n",
    "        #is there a difference between what this returns and the original cycelgan does?\n",
    "        return discriminator_model\n",
    "        \n",
    "#         model = Sequential()\n",
    "#         model.add(Dense(4*self.data_dim))#(disc_input))\n",
    "#         model.add(Activation('relu'))\n",
    "#         #model.add(Dropout(0.25))\n",
    "#         model.add(Dense(2*self.data_dim))\n",
    "#         model.add(Activation('relu'))\n",
    "#         model.add(Dense(1))\n",
    "#         model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "#         discriminator_model = model #Model(inputs=[disc_input], outputs=[x])\n",
    "#         #visualize_model(discriminator_model)\n",
    "#         print(\"DISCRIMINATOR\")\n",
    "#         #model.summary()\n",
    "#         #is there a difference between what this returns and the original cycelgan does?\n",
    "#         return discriminator_model\n",
    "    \n",
    "    def train(self, epochs, batch_size=1, sample_interval=50):\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        valid = np.ones((batch_size,)) #+ self.disc_patch)\n",
    "        fake = np.zeros((batch_size,)) #+ self.disc_patch)\n",
    "        self.g_AB.summary()\n",
    "        self.g_BA.summary()\n",
    "        self.d_A.summary()\n",
    "        self.d_B.summary()\n",
    "        self.n_batches = int(min(len(data_A), len(data_B)) / batch_size)\n",
    "        #total_samples = self.n_batches * batch_size\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(self.n_batches-1):\n",
    "                #randomly shuffle data?\n",
    "                \n",
    "                #take the corresponding \"Batch size\" number of elements\n",
    "                batch_A = data_A[i*batch_size:(i+1)*batch_size]\n",
    "                batch_B = data_B[i*batch_size:(i+1)*batch_size]\n",
    "                #put them through this thing\n",
    "                \n",
    "                \n",
    "                # ----------------------\n",
    "                #  Train Discriminators\n",
    "                # ----------------------\n",
    "               # print(imgs_A.shape)\n",
    "\n",
    "                # Translate images to opposite domain\n",
    "                fake_B = self.g_AB.predict(batch_A)\n",
    "                fake_A = self.g_BA.predict(batch_B)\n",
    "                #print(fake_A.shape)\n",
    "                #print(fake_B.shape)\n",
    "                # Train the discriminators (original images = real / translated = Fake)\n",
    "                dA_loss_real = self.d_A.train_on_batch(batch_A, valid)\n",
    "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
    "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "\n",
    "                dB_loss_real = self.d_B.train_on_batch(batch_B, valid)\n",
    "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
    "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "\n",
    "                # Total disciminator loss\n",
    "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
    "\n",
    "\n",
    "                # ------------------\n",
    "                #  Train Generators\n",
    "                # ------------------\n",
    "\n",
    "                # Train the generators\n",
    "                g_loss = self.combined.train_on_batch([batch_A, batch_B],\n",
    "                                                        [valid, valid,\n",
    "                                                        batch_A, batch_B,\n",
    "                                                        batch_A, batch_B])\n",
    "\n",
    "                elapsed_time = datetime.datetime.now() - start_time\n",
    "\n",
    "                # Plot the progress\n",
    "                print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" \\\n",
    "                                                                        % ( epoch, epochs,\n",
    "                                                                            i, self.n_batches,\n",
    "                                                                            d_loss[0], 100*d_loss[1],\n",
    "                                                                            g_loss[0],\n",
    "                                                                            np.mean(g_loss[1:3]),\n",
    "                                                                            np.mean(g_loss[3:5]),\n",
    "                                                                            np.mean(g_loss[5:6]),\n",
    "                                                                            elapsed_time))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if i % sample_interval == 0:\n",
    "                    self.sample_data(epoch, i)\n",
    "\n",
    "    def sample_data(self, epoch, batch_i):\n",
    "        os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n",
    "       # r, c = 2, 3\n",
    "\n",
    "        orig2, pic_data_A, pic_data_B= gen_data()\n",
    "        \n",
    "    \n",
    "        # Translate images to the other domain\n",
    "        fake_B = self.g_AB.predict(pic_data_A)\n",
    "        fake_A = self.g_BA.predict(pic_data_B)\n",
    "        # Translate back to original domain\n",
    "        reconstr_A = self.g_BA.predict(fake_B)\n",
    "        reconstr_B = self.g_AB.predict(fake_A)\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(131)\n",
    "\n",
    "        ax1.scatter(pic_data_A[:, 0], pic_data_A[:,1], s=25, c='b', marker=\"s\", label='original')\n",
    "        ax1.scatter(fake_A[:,0], fake_A[:,1], c='r', s=25, marker=\"o\", label='fake')\n",
    "        ax1.scatter(reconstr_A[:,0], reconstr_A[:,1], s=25, c='g', marker=\"o\", label='reconstructed')\n",
    "        plt.legend(loc='upper left');\n",
    "        \n",
    "        ax2=fig.add_subplot(132)\n",
    "        ax2.scatter(pic_data_B[:, 0], pic_data_B[:,1], s=25, c='b', marker=\"s\", label='original')\n",
    "        ax2.scatter(fake_B[:,0], fake_B[:,1], s=25, c='r', marker=\"o\", label='fake')\n",
    "        ax2.scatter(reconstr_B[:,0], reconstr_B[:,1], s=25, c='g', marker=\"o\", label='reconstructed')\n",
    "        plt.legend(loc='upper left');\n",
    "        \n",
    "        ax3=fig.add_subplot(133)\n",
    "        ax3.scatter(pic_data_B[:, 0], pic_data_B[:,1], s=25, c='b', marker=\"s\", label='originalB')\n",
    "        ax3.scatter(fake_B[:,0], fake_B[:,1], s=25, c='r', marker=\"o\", label='fakeB')\n",
    "        ax3.scatter(reconstr_B[:,0], reconstr_B[:,1], s=25, c='g', marker=\"o\", label='reconstructedB')\n",
    "        ax3.scatter(pic_data_A[:, 0], pic_data_A[:,1], s=25, c='b', marker=\"s\", label='originalA')\n",
    "        ax3.scatter(fake_A[:,0], fake_A[:,1], c='r', s=25, marker=\"o\", label='fakeA')\n",
    "        ax3.scatter(reconstr_A[:,0], reconstr_A[:,1], s=25, c='g', marker=\"o\", label='reconstructedA')\n",
    "        plt.legend(loc='upper left');\n",
    "        \n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "        fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Cell where I changed the learning rate, 5x slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    gan = CycleGAN2(data_A, data_B)\n",
    "    gan.train(epochs=400, batch_size=10, sample_interval=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bigger discriminator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_lr0002_400epochs_50discloss = CycleGAN2(data_A, data_B)\n",
    "gan_lr0002_400epochs_50discloss.train(epochs=400, batch_size=10, sample_interval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function numpy.lib.utils._Deprecate.__call__.<locals>.newfunc(*args, **kwds)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.misc.imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_lr0002_400epochs_50discloss = CycleGAN2(data_A, data_B)\n",
    "gan_lr0002_400epochs_50discloss.train(epochs=400, batch_size=10, sample_interval=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transpose images to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "o, a, b =gen_data((10,10), 3, (-7,6), .25, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(121)\n",
    "\n",
    "ax1.scatter(o[:, 0], o[:,1], s=25, c='b', marker=\"s\", label='original')\n",
    "ax1.scatter(a[:,0], a[:,1], c='r', s=25, marker=\"o\", label='a')\n",
    "ax1.scatter(b[:,0], b[:,1], s=25, c='g', marker=\"o\", label='b')\n",
    "plt.legend(loc='upper left');\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-17355687edec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgridreal\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgridreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "grid=np.meshgrid(range(-10,10), range(-30,10))\n",
    "gridreal= np.array([[grid[0].flatten()[i], grid[1].flatten()[i]] for i in range(20*40)])\n",
    "vals=gan.d_A.predict(gridreal)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = grid[0].flatten()[vals > 0.5]\n",
    "valid_y = grid[1].flatten()[vals > 0.5]\n",
    "\n",
    "fake_x = grid[0].flatten()[vals < 0.5]\n",
    "fake_y = grid[1].flatten()[vals < 0.5]\n",
    "\n",
    "plt.scatter(valid_x, valid_y)\n",
    "plt.scatter(fake_x, fake_y)\n",
    "plt.scatter(data_A[:,0], data_A[:,1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
